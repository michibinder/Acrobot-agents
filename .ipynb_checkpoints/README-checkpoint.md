## Acrobot-agents

Development of multiple agents learning the acrobot environment of the OpenAI Gym.

First group of agents uses neuronal networks to estimate the action-value function Q of the continous state, discrete actions environment. These are semi-gradient Q and SARSA algorithms in a classic and a DQN (deep Q network) approach.

Second group of agents uses neuronal networks to estimate the policy directly. These are Monte-Carlo policy gradient (REINFORCE algorithm), Monte-Carlo Advantage Actor-Critic & TD Advantage Actor-Critic agents.

